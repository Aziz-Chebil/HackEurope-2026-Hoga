{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "827e231c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets = load_dataset(\n",
    "    \"json\", \n",
    "    data_files={\n",
    "        \"train\": \"archive/train.json\", \n",
    "        \"validation\": \"archive/dev.json\", \n",
    "        \"test\": \"archive/test.json\"\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dca2faf",
   "metadata": {},
   "source": [
    "On fait marcher le modèle de Greg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb269956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"graph\")\n",
    "\n",
    "from graph.predict import predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e47439bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using local data: C:\\Users\\octav\\OneDrive\\Bureau\\hackathon\\HackEurope-2026-Hoga\\archive\n",
      "Loading dataset splits...\n",
      "  Loading train.json...\n",
      "  Loading dev.json...\n",
      "  Loading test.json...\n",
      "  Labeled users: 11826 (train=8278, val=2365, test=1183)\n",
      "  Total nodes: 191582 (11826 labeled, 179756 unlabeled neighbors)\n",
      "Building edge index...\n",
      "  Edges: 208716 (following=105701, follower=103015)\n",
      "Extracting node features...\n",
      "  Feature matrix: torch.Size([191582, 20])\n",
      "  Labels: 5237 human, 6589 bot, 179756 unlabeled\n",
      "  Masks: train=8278, val=2365, test=1183\n"
     ]
    }
   ],
   "source": [
    "probas = predict(list(raw_datasets[\"test\"]), model_type=\"rgcn\")\n",
    "prob1 = probas[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b93e6df",
   "metadata": {},
   "source": [
    "On fait marcher le modèle d'Hadrien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789ee121",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02836c63",
   "metadata": {},
   "source": [
    "On fait marcher le modèle de Aziz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bb607931",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aziz_code import create_csv, create_features3, predict_bot_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fd0ec328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "# ── Charger le modèle ─────────────────────────────────────────────────────────\n",
    "with open('bot_detector.pkl', 'rb') as f:\n",
    "    saved = pickle.load(f)\n",
    "model    = saved['model']\n",
    "features = saved['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c3de4626",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "create_csv() missing 2 required positional arguments: 'dev_data' and 'test_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df = \u001b[43mcreate_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_datasets\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtest\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m df = create_features3(df)\n\u001b[32m      4\u001b[39m results = predict_bot_probability(df, model,features)\n",
      "\u001b[31mTypeError\u001b[39m: create_csv() missing 2 required positional arguments: 'dev_data' and 'test_data'"
     ]
    }
   ],
   "source": [
    "df = create_csv(raw_datasets[\"test\"])\n",
    "df = create_features3(df)\n",
    "\n",
    "results = predict_bot_probability(df, model,features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2869d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c24d403",
   "metadata": {},
   "source": [
    "on fait les trucs qui contiendront les différentes méthodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3b25d2",
   "metadata": {},
   "source": [
    "On a df_prob qui a prob1, prob2, prob3 et label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66629242",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc1 = accuracy_score(df_prob[\"label\"], (df_prob[\"prob1\"] >= 0.5).astype(int))\n",
    "acc2 = accuracy_score(df_prob[\"label\"], (df_prob[\"prob2\"] >= 0.5).astype(int))\n",
    "acc3 = accuracy_score(df_prob[\"label\"], (df_prob[\"prob3\"] >= 0.5).astype(int))\n",
    "\n",
    "print(f\"Acc modèle 1: {acc1:.4f}\")\n",
    "print(f\"Acc modèle 2: {acc2:.4f}\")\n",
    "print(f\"Acc modèle 3: {acc3:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0767a546",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultprob = pd.DataFrame()\n",
    "df_pred = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9e9a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Moyenne normale des probas\n",
    "df_resultprob[\"avg\"] = df_prob[[\"prob1\", \"prob2\", \"prob3\"]].mean(axis=1)\n",
    "df_pred[\"avg\"] = (df_resultprob[\"avg\"] >= 0.5).astype(int)\n",
    "print(f\"Acc avg: {accuracy_score(df_prob['label'], df_pred['avg']):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deeeb811",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Moyenne pondérée par les accuracy\n",
    "total = acc1 + acc2 + acc3\n",
    "df_resultprob[\"wavg\"] = (acc1 * df_prob[\"prob1\"] + acc2 * df_prob[\"prob2\"] + acc3 * df_prob[\"prob3\"]) / total\n",
    "df_pred[\"wavg\"] = (df_resultprob[\"wavg\"] >= 0.5).astype(int)\n",
    "print(f\"Acc wavg: {accuracy_score(df_prob['label'], df_pred['wavg']):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cd2544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ElasticNet\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "lam = 0.01\n",
    "l1_ratio = 0.5\n",
    "\n",
    "enet = ElasticNet(alpha=lam, l1_ratio=l1_ratio)\n",
    "enet.fit(df_prob[[\"prob1\", \"prob2\", \"prob3\"]], df_prob[\"label\"])\n",
    "df_resultprob[\"enet\"] = enet.predict(df_prob[[\"prob1\", \"prob2\", \"prob3\"]]).clip(0, 1)\n",
    "df_pred[\"enet\"] = (df_resultprob[\"enet\"] >= 0.5).astype(int)\n",
    "print(f\"Acc ElasticNet (lambda={lam}, l1_ratio={l1_ratio}): {accuracy_score(df_prob['label'], df_pred['enet']):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c0389b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Régression logistique\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "df_resultprob[\"logreg\"] = np.nan\n",
    "for train_idx, val_idx in kf.split(df_prob):\n",
    "    logreg = LogisticRegression()\n",
    "    logreg.fit(df_prob.loc[train_idx, [\"prob1\", \"prob2\", \"prob3\"]], df_prob.loc[train_idx, \"label\"])\n",
    "    df_resultprob.loc[val_idx, \"logreg\"] = logreg.predict_proba(df_prob.loc[val_idx, [\"prob1\", \"prob2\", \"prob3\"]])[:, 1]\n",
    "\n",
    "df_pred[\"logreg\"] = (df_resultprob[\"logreg\"] >= 0.5).astype(int)\n",
    "print(f\"Acc LogReg (KFold): {accuracy_score(df_prob['label'], df_pred['logreg']):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88330ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM\n",
    "import lightgbm as lgb\n",
    "\n",
    "df_resultprob[\"lgbm\"] = np.nan\n",
    "for train_idx, val_idx in kf.split(df_prob):\n",
    "    lgb_model = lgb.LGBMClassifier(n_estimators=100, max_depth=3, learning_rate=0.1, verbose=-1)\n",
    "    lgb_model.fit(df_prob.loc[train_idx, [\"prob1\", \"prob2\", \"prob3\"]], df_prob.loc[train_idx, \"label\"])\n",
    "    df_resultprob.loc[val_idx, \"lgbm\"] = lgb_model.predict_proba(df_prob.loc[val_idx, [\"prob1\", \"prob2\", \"prob3\"]])[:, 1]\n",
    "\n",
    "df_pred[\"lgbm\"] = (df_resultprob[\"lgbm\"] >= 0.5).astype(int)\n",
    "print(f\"Acc LightGBM (KFold): {accuracy_score(df_prob['label'], df_pred['lgbm']):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
