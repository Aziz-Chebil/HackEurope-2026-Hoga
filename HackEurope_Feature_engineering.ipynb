{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "iI6iJbMppxvt",
        "outputId": "1e3d09f5-0f3d-466d-ce9f-20ab50601f1d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'train.json'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-260833646.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mdev_data\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mload_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dev.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtest_data\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mload_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-260833646.py\u001b[0m in \u001b[0;36mload_json\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# ── Load all splits ───────────────────────────────────────────────────────────\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train.json'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# ── Load all splits ───────────────────────────────────────────────────────────\n",
        "def load_json(filepath):\n",
        "    with open(filepath, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "    return data\n",
        "\n",
        "train_data = load_json(\"train.json\")\n",
        "dev_data   = load_json(\"dev.json\")\n",
        "test_data  = load_json(\"test.json\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_entries(data, split_name):\n",
        "    rows = []\n",
        "    for entry in data:\n",
        "        profile = entry.get('profile', {}) or {}\n",
        "        tweets  = entry.get('tweet', [])  or []\n",
        "\n",
        "        row = {\n",
        "            # Identity\n",
        "            'ID'              : entry.get('ID'),\n",
        "            'split'           : split_name,\n",
        "            'label'           : int(entry.get('label')),  # ← fixed\n",
        "\n",
        "\n",
        "            # Profile features\n",
        "            'screen_name'     : profile.get('screen_name', ''),\n",
        "            'name'            : profile.get('name', ''),\n",
        "            'description'     : profile.get('description', ''),\n",
        "            'location'        : profile.get('location', ''),\n",
        "            'followers_count' : profile.get('followers_count', 0),\n",
        "            'friends_count'   : profile.get('friends_count', 0),\n",
        "            'statuses_count'  : profile.get('statuses_count', 0),\n",
        "            'favourites_count': profile.get('favourites_count', 0),\n",
        "            'listed_count'    : profile.get('listed_count', 0),\n",
        "            'verified'        : profile.get('verified', False),\n",
        "            'created_at'      : profile.get('created_at', ''),\n",
        "            'default_profile' : profile.get('default_profile', False),\n",
        "            'default_profile_image': profile.get('default_profile_image', False),\n",
        "\n",
        "            # Tweet features\n",
        "            'tweet_count'     : len(tweets),\n",
        "            'tweets': [t for t in tweets if isinstance(t, str)],\n",
        "\n",
        "            # Graph features\n",
        "            'neighbors'       : entry.get('neighbor', {}) or {},\n",
        "            'domain'          : entry.get('domain', ''),\n",
        "        }\n",
        "        rows.append(row)\n",
        "    return rows\n"
      ],
      "metadata": {
        "id": "f9ycacujqA1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_rows = parse_entries(train_data, 'train')\n",
        "dev_rows   = parse_entries(dev_data,   'dev')\n",
        "test_rows  = parse_entries(test_data,  'test')\n",
        "train_df = pd.DataFrame(train_rows + dev_rows)  # combine train and dev\n",
        "test_df  = pd.DataFrame(test_rows)\n",
        "\n",
        "train_df.to_csv(\"train.csv\", index=False)\n",
        "test_df.to_csv(\"test.csv\",  index=False)\n"
      ],
      "metadata": {
        "id": "9HFBuuBZqBcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df  = pd.read_csv(\"test.csv\")\n"
      ],
      "metadata": {
        "id": "-2OKywU2qDeb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Importing the modules\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n"
      ],
      "metadata": {
        "id": "6Y27xclSqIB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "# ── Feature Engineering ───────────────────────────────────────────────────────\n",
        "def create_features3(df):\n",
        "    df = df.copy()\n",
        "\n",
        "    # 1. Followers / Friends ratio\n",
        "    df['followers_count'] = pd.to_numeric(df['followers_count'], errors='coerce').fillna(0)\n",
        "    df['friends_count']   = pd.to_numeric(df['friends_count'],   errors='coerce').fillna(0)\n",
        "    df['follow_ratio']    = df['followers_count'] / (df['friends_count'] + 1)  # +1 to avoid division by zero\n",
        "\n",
        "    df['default_profile']       = df['default_profile']\n",
        "    df['default_profile_image'] = df['default_profile_image']\n",
        "    df['verified']              = df['verified']\n",
        "\n",
        "    # 3. Description length\n",
        "    df['description_length'] = df['description'].fillna('').apply(len)\n",
        "\n",
        "    # 4. Verified (boolean → int)\n",
        "\n",
        "\n",
        "    # 5. Numeric columns\n",
        "    df['statuses_count'] = pd.to_numeric(df['statuses_count'], errors='coerce').fillna(0)\n",
        "    df['listed_count']   = pd.to_numeric(df['listed_count'],   errors='coerce').fillna(0)\n",
        "\n",
        "    from datetime import datetime, timezone\n",
        "\n",
        "    df['account_age_days'] = df['created_at'].apply(\n",
        "    lambda x: (datetime.now(timezone.utc) - pd.to_datetime(x, errors='coerce', utc=True)).days\n",
        "    if pd.notnull(x) else 0\n",
        "    )\n",
        "\n",
        "\n",
        "    # Tweets par jour (activité)\n",
        "    df['tweets_per_day'] = df['statuses_count'] / (df['account_age_days'] + 1)\n",
        "        # Convertir la colonne tweets depuis string CSV vers liste\n",
        "    df['tweets'] = df['tweets'].apply(\n",
        "        lambda x: eval(x) if isinstance(x, str) else x\n",
        "    )\n",
        "\n",
        "        # Ratio de retweets\n",
        "    df['retweet_ratio'] = df['tweets'].apply(\n",
        "        lambda x: sum(1 for t in x if t.startswith('RT ')) / (len(x) + 1)\n",
        "    )\n",
        "     # Ratio de tweets avec URLs\n",
        "    df['url_ratio'] = df['tweets'].apply(\n",
        "        lambda x: sum(1 for t in x if 'https://' in t) / (len(x) + 1)\n",
        "    )\n",
        "    # Longueur moyenne des tweets\n",
        "    df['avg_tweet_length'] = df['tweets'].apply(\n",
        "        lambda x: sum(len(t) for t in x) / (len(x) + 1)\n",
        "    )\n",
        "        # Diversité des hashtags\n",
        "    df['hashtag_diversity'] = df['tweets'].apply(\n",
        "        lambda x: len(set(re.findall(r'#\\w+', ' '.join(x)))) / (len(x) + 1)\n",
        "    )\n",
        "\n",
        "\n",
        "    return df\n",
        "\n",
        "new_train_df2 = create_features3(train_df)\n",
        "new_test_df2  = create_features3(test_df)"
      ],
      "metadata": {
        "id": "-rx65mzIqTMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ── Define Features & Target ──────────────────────────────────────────────────\n",
        "features = [\n",
        "    'follow_ratio',\n",
        "    'default_profile',\n",
        "    'default_profile_image',\n",
        "    'description_length',\n",
        "    'statuses_count',\n",
        "    'verified',\n",
        "    'listed_count',\n",
        "    'account_age_days',   # ← ajouter\n",
        "    'tweets_per_day',\n",
        "    'retweet_ratio',\n",
        "    'url_ratio',\n",
        "    'avg_tweet_length',\n",
        "    'hashtag_diversity'\n",
        "\n",
        "]\n",
        "\n",
        "X_train = new_train_df2[features]\n",
        "y_train = new_train_df2['label']\n",
        "\n",
        "X_test  = new_test_df2[features]\n",
        "y_test  = new_test_df2['label']\n",
        "\n",
        "\n",
        "bool_cols = ['default_profile', 'default_profile_image', 'verified']\n",
        "\n",
        "for col in bool_cols:\n",
        "    X_train[col] = X_train[col].astype(str).str.strip().str.lower().eq('true')\n",
        "    X_test[col]  = X_test[col].astype(str).str.strip().str.lower().eq('true')\n",
        "\n",
        "# ── Train ─────────────────────────────────────────────────────────────────────\n",
        "model = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    class_weight='balanced',  # gère le déséquilibre bots/humains\n",
        "    random_state=42\n",
        ")\n",
        "model.fit(X_train2, y_train2)\n",
        "y_pred2 = model.predict(X_test2)\n",
        "print(\"=== Classification Report ===\")\n",
        "print(classification_report(y_test2, y_pred2, target_names=['Human', 'Bot']))\n",
        "\n",
        "print(\"=== Confusion Matrix ===\")\n",
        "cm = confusion_matrix(y_test2, y_pred2)\n",
        "print(pd.DataFrame(cm,\n",
        "    index=['Actual Human', 'Actual Bot'],\n",
        "    columns=['Predicted Human', 'Predicted Bot']))\n",
        "\n",
        "print(\"\\n=== Feature Importance ===\")\n",
        "importance_df = pd.DataFrame({\n",
        "    'feature'   : features,\n",
        "    'importance': model.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(importance_df.to_string(index=False))"
      ],
      "metadata": {
        "id": "Ht3UmUNgqV1w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}